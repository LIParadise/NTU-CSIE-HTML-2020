# Week 2

## Revisit The Credit Card Problem

Assume that the data is generated by the $f$...

But what $H$ could we have?

## The Perceptron

$0$ is often ignored, including this linear model we're discussing.

'Perceptron' (感知器): a traditional way to achieve ML

During this course we often use *column vectors* to simplify notation, e.g. $v^{T} \cdot w$ means taking inner product.

If we use linear (binary) classifiers, or perceptrons, we're effectively stating that our $H$ shall be the set of all *surface* in a (multi-)dimensional space.

## Select $h$ from $H$: *PLA*

Intuitively we may want that $g$ to be more agreeing with $f$ on $D$ would be better; this is a bold and un-verified intuition, which would be discussed throughout the semester.

Notice our $H$ is already infinite in size! We need an efficient algorithm to find $g$.

Turns out we can! Suppose we have an initial line, we could correct it with data points.

> If $f$ says $+1$ but machine thinks it's $-1$, either in *inner product* perspective or in genuine Euclidean space perspective, we find that our $w$ is pointing a direction far from that of $x$, hence we shall modify $w$ such that it's pointing more closer to where $x$ is pointing. Vice versa.

Notice we didn't address *how to check if there's wrong point* and *how to find wrong point* here.

Claim: Under certain circumstances, PLA is guaranteed to halt

Notice when PLA halts, it gives us correct answer on $D$, but anything outside $D$ is not assured.

That $y_n w^{T}_{t+1} x_n \geq y_n w^{T}_{t} x_n$ suggests the calculated result, $w^{T}_{t+1} x_n$, leans more to $y_n$, which illustrates the intuition behind PLA.

### Proof

Proposition: (slide 02_handout.pdf 14/22 ~ 15/22)
Given *linear separable* set $D$, the PLA is guaranteed to halt within ${ \left( \frac{R}{d} \right) }^2$ moves, where $R\overset{\Delta}{=} \max\limits_{\bm{x}_n \in D}{\lVert \bm{x}_n\rVert}$, $d\overset{\Delta}{=} \min\limits_{\bm{x}_n \in D}{y_n \frac{\bm{w}_f^T}{ \lVert \bm{w}_f \rVert}\bm{x}_n}$, and $\bm{w}_f$ being such that $d>0$.

Notice we have $$\bm{w}_f^T \bm{w}_{t+1} \geq \bm{w}_f^T \bm{w}_{t} + \min\limits_{\bm{x}_n \in D}{y_n \bm{w}_f^T \bm{x}_n} = \bm{w}_f^T w_{t} + \lVert \bm{w}_f \rVert \times d \\ \implies \bm{w}_f^T \bm{w}_{t+1} \geq t\times d \times \lVert \bm{w}_f \rVert$$ let's call it formula 1.
We also have that $${\lVert \bm{w}_{t+1} \rVert}^2 \leq {\lVert \bm{w}_{t} \rVert}^2 + R^2 \implies {\lVert \bm{w}_{t+1} \rVert}^2 \leq t\times R^2$$ let's call it formula 2.
Turn $\text{LHS}$ of formula 1 into unit vectors, we have $$1 \geq \frac{ \bm{w}_f^T \bm{w}_{t+1}}{ \lVert \bm{w}_f \rVert \lVert \bm{w}_{t+1} \rVert} \geq \frac{d\sqrt{t}}{R}$$
Hence at most PLA takes $\dfrac{R^2}{d^2}$ times to complete.<div style="text-align: right">$\square$</div>

## Non-Linear-Separable Data?

1. We don't know a-priori if it's linear separable
2. Even if we know it's linear separable, we don't know speed of convergence, since we don't know $W_f$ and $\rho$

## Question

- (slide 02_handout.pdf 12/22)
  Shall be first take transpose: $w_{t+1}^{T} \leftarrow w_{t}^T + y_n\bm{x}_n$
  And then multiply both side with $y_n \bm{x}_n$?
