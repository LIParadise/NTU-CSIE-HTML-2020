# Overfit

## Low Complexity with Noise versus High Complexity with No Noise

### Question

1. Why is noise related to the learning curve?
2. In the "target complexity acts like noise when your hypothesis have too low complexity compared to the target", we say that it's since our hypothesis just can't handle such information. How is this related to the criteria that "overfitting needs high VC dimension". In this case, it's more like our VC dimension is too low...
  - See the experiment data. When $\text{target complexity} >> \text{model 1 VC} >> \text{model 2 VC}$, we have overfitting (?)
3. In the experiment, we seem to only focus on the delta of $E_\text{in}$, but overfitting needs both *decrease of $E_\text{in}$* and *increase of $E_\text{out}$*, the latter of which isn't illustrated here.
  - Nah ya read it wrong. It's drawing the difference between $E_\text{out}$.

## Experiment Data to Illustrate Noise versus Target Complexity

> 簡單的都學不好了，學那些太難的沒什麼屁用；對於簡單的hypothesis set，我們不應該期待太複雜的 target 會有好的學習效果，是為 deterministic noise

## How to Fight Overfit

### Data Cleaning/Pruning

If we don't have domain knowledge or good noise model, our only way may be left with trust the simple model.
However with soft model and regularization, as shall be introduced in next lecture, their inherent resiliency/robustness agains noise makes it even harder to do.
It's recommended that these are done when you collect data: the "buying diamond on PCHome" example: sometimes outliers are extreme bizzare and are relatively safe to ignore.

### Data Hinting

Also called *virtual example*; recently got the name *data augementation*.
Still rely on human learning/domain knowledge to help determine how to generate these extra data.
However the benefit is great if you're low on data or your model, such as DL, just need that much.

DL needs to the 特徵轉換 \(\phi\), this step likes large data. But when it proceeds to the data classification step, these augementation may not be as well.

## QA

### DL have seemly stupidly large VC dimension.

> OK 這樣講有點奇怪，一樣就是,用參數的數量來說, DL 看起來非常的 powerful ，可是其實，很多的 deeplearning 的模型的發展， 裡面蘊含了一些，例如說， 人類的design，一些optimization的design，蘊含了也許本身那個問題裡面的那些所有 local maxima 等等，讓我們其實很難解到 理論上的那個 deep learning model 的那個最佳解; 那當一個模型其實沒辦法達成它所宣稱的那個最佳解的時候， 那麼那個模型其實也沒有它所宣稱的那麼 powerful

### How to Augmentation?

- 匯率
  台幣對美金
  美金對台幣
  suppose 匯率問題具有對稱性
  Again, back to domain knowledge

- 颱風
  rotate
  shift is not good, since we need to know the location of 颱風眼
  科氏力
  南半球/北半球

More domain knowledge example include *monotonic function* --> the hypothesis shall not jump up and down; may add more monotonic examples.

- Adversarial Examples

Let the machine tell which examples would confuse them most, and try add them to training data. This is an example of augementation but less related to domain knowledge.

### How to determine noise and outliers in general?

Short answer, you don't.

Longer answer, you may need models on the noise.
Moreover, if you prune, you may lose the ability to detect extreme examples.

### How to differentiate noise and target complexity?

Short answer, again, you can't, since we don't know target function.

Again, with domain knowledge, you may have a hint.

But when you have nothing, you just can't.

## Misc

> 我自己喜歡做機器學習的原因之一是，有時候做一做，設計一些方法、或者是說看到一些現象，都會想想這對自己生涯上的學習到底有什麼樣的啟發、或者是影響，或者是怎麼樣可以分享給大家
