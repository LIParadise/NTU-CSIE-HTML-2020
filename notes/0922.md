# Select $g$ from $H$

Think of a way to correctify a our $g$ by adjusting its weight vector $w_0$

## PLA

Our data are all intrinsically $\mathbb{R}^n$ with the additional $0\text{th}$ dimension; in such spaces, a multi-dimensional plane is of $n-1$ dimensions, which is fully determined in such space with $n$ parameters $\implies$ we kinda have an additional degree of freedom in choosing $w$!
Such degree of freedom is not necessary (?) in PLA, but our version of proof find that useful: think of length versus inner products...
When running PLA, our function $g$ is a multi-dimensional plane on $\mathbb{R}^{n+1}$, and all data points on the $0\text{th}$ are assumed to be at $1$.

『第一個較為廣為人之的機器學習演算法』

看$x$的方向，旋轉我們的$w$向量
應為positive，預測為negative，代表需要轉向$x$的方向; 不妨用$w^{'}=w+x$
『轉向$x$的方向才有可能把$x$弄對』
應為negative，預測為positive，代表需要轉離$x$的方向; 不妨用$w^{'}=w-x$

Initially we often choose $w=\vec{0}$, where all data we predict it's negative.

If PLA halts, we choose $g = w_\text{PLA}$

『2D平面上其實會有$x_0 = 1$或是$x_0 = 0$的平移』

『這個多的自由度、還沒normalize之類的分割，可以讓我們比較方便地設計演算法，並且也比較容易argue它會不會halt』

Q: in-separable data; guaranteed to be strictly increasing better?
A: Nope, it's not guaranteed; you could easily find counter example with in-separable data.
   cf: pocket algorithm

Q: PLA seems to be depends on the order we choose the wrong points?
A: Yep

Q: why $w_0$ only -1 or 1?

Q: limit PLA direction change quantity such that it's quicker to find result?
A: You can, but higher order you can't quite figure out what your *angle* is
   PLA is good in that it just works in multi-dimensional space.
   - 2D we could just use convex hull

Q: $w_0$ is limited to integer; seems quite a strict regulation?
A: we still have other dimensions of freedom that's not limited in size, so that shall not be a problem.

### *Linear Separable*

Assume Linear Separable, does PLA guarantee to halt?

Linear Separable $\implies$ exists $w_f$
We could argue that $w_{t+1}^{T} \cdot w_f > w_{t}^{T} \cdot w_f$

Q: We don't limit length of vectors, so inner product don't quite give use they are approaching? Maybe normalizing them before inner product?
Spoiler: *We need to choose only the __wrong__ points!*